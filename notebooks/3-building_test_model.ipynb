{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installing fasttext package if needed\n",
    "!pip -q install -U fasttext seaborn gensim scikit-learn numpy pandas\n",
    "\n",
    "#https://radimrehurek.com/gensim/models/fasttext.html\n",
    "#https://colab.research.google.com/drive/1_jZOV8G-zr11aHYcgV9IFpCgObA4Br1E#scrollTo=62Ui7K--RZry\n",
    "#https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import Word2Vec\n",
    "#from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "#from gensim.test.utils import datapath, get_tmpfile\n",
    "\n",
    "#import fasttext\n",
    "#import fasttext.util\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        print('func:{} took: {:2.4f} sec'.format(f.__name__, te-ts))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.read_pickle('../outputs/df_files.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/home/jovyan/shared/C_amc_141/R_amc_3.1_12921/203_vert_spacy_rftt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5706\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for filepath in df_files[0:25].path:\n",
    "    path = os.path.join(folder, filepath)\n",
    "    response = parser.parse(path)\n",
    "    response = list(response)\n",
    "    responses.extend(response)\n",
    "print(len(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining values for parameters\n",
    "embedding_size = 100\n",
    "window_size = 5\n",
    "min_word = 2\n",
    "down_sampling = 1e-2\n",
    "\n",
    "\n",
    "model_ft = FastText(responses,\n",
    "                    size=embedding_size,\n",
    "                    window=window_size,\n",
    "                    min_count=min_word,\n",
    "                    sample=down_sampling,\n",
    "                    workers = -1,\n",
    "                    sg=1,\n",
    "                    iter=100)\n",
    "\n",
    "model_wv = Word2Vec(sentences=responses, \n",
    "                    size=embedding_size, \n",
    "                    window=window_size, \n",
    "                    min_count=min_word,\n",
    "                    sample=down_sampling,\n",
    "                    workers=-1, \n",
    "                    sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"Politiker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Politikern', 0.8484600186347961),\n",
       " ('Politikers', 0.840560793876648),\n",
       " ('Politikerin', 0.7620358467102051),\n",
       " ('politiker', 0.7289317846298218),\n",
       " ('Politiken', 0.6909029483795166),\n",
       " ('Politik', 0.6865997910499573),\n",
       " ('Politika', 0.6759346723556519),\n",
       " ('Politi', 0.6442322731018066),\n",
       " ('politikers', 0.618487536907196),\n",
       " ('Politikerinnen', 0.6086919903755188)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.wv.most_similar(word, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bravo', 0.37358352541923523),\n",
       " ('kommentarlos', 0.3728218972682953),\n",
       " ('Arena', 0.3688957691192627),\n",
       " ('Gilligan', 0.36179256439208984),\n",
       " ('Meyer', 0.35840052366256714),\n",
       " ('prominente', 0.3579070568084717),\n",
       " ('ÖHV', 0.3571491539478302),\n",
       " ('entscheidende', 0.3562243580818176),\n",
       " ('bezichtigten', 0.3510328233242035),\n",
       " ('Berühmtheiten', 0.3474709987640381)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wv.wv.most_similar(word, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6661\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for filepath in df_files[25:50].path:\n",
    "    path = os.path.join(folder, filepath)\n",
    "    response = parser.parse(path)\n",
    "    response = list(response)\n",
    "    responses.extend(response)\n",
    "    \n",
    "print(len(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.build_vocab(responses, update=True)  # Update the vocabulary\n",
    "model_ft.train(responses, total_examples=len(responses), epochs=model_ft.epochs)\n",
    "\n",
    "model_wv.build_vocab(responses, update=True)  # Update the vocabulary\n",
    "model_wv.train(responses, total_examples=len(responses), epochs=model_wv.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Politikern', 0.8484600186347961),\n",
       " ('Politikers', 0.840560793876648),\n",
       " ('Politikerin', 0.7620358467102051),\n",
       " ('politiker', 0.7289317846298218),\n",
       " ('Politiken', 0.6909029483795166),\n",
       " ('Politik', 0.6865997910499573),\n",
       " ('Politika', 0.6759346723556519),\n",
       " ('litiker', 0.6655194759368896),\n",
       " ('Politi', 0.6442322731018066),\n",
       " ('Exilpolitiker', 0.6252126693725586)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.wv.most_similar(word, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Warenhaus', 0.43683958053588867),\n",
       " ('Peiritsch', 0.4329608082771301),\n",
       " ('2150', 0.3990057706832886),\n",
       " ('Bravo', 0.37358352541923523),\n",
       " ('kommentarlos', 0.3728218972682953),\n",
       " ('Arena', 0.3688957691192627),\n",
       " ('Gilligan', 0.36179256439208984),\n",
       " ('Meyer', 0.35840052366256714),\n",
       " ('prominente', 0.3579070568084717),\n",
       " ('ÖHV', 0.3571491539478302)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wv.wv.most_similar(word, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6269\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for filepath in df_files[50:75].path:\n",
    "    path = os.path.join(folder, filepath)\n",
    "    response = parser.parse(path)\n",
    "    response = list(response)\n",
    "    responses.extend(response)\n",
    "\n",
    "print(len(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.build_vocab(responses, update=True)  # Update the vocabulary\n",
    "model_ft.train(responses, total_examples=len(responses), epochs=model_ft.epochs)\n",
    "\n",
    "model_wv.build_vocab(responses, update=True)  # Update the vocabulary\n",
    "model_wv.train(responses, total_examples=len(responses), epochs=model_wv.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Politikern', 0.8484600186347961),\n",
       " ('Politikers', 0.840560793876648),\n",
       " ('Politikerin', 0.7620358467102051),\n",
       " ('politiker', 0.7289317846298218),\n",
       " ('Politiken', 0.6909029483795166),\n",
       " ('Politik', 0.6865997910499573),\n",
       " ('Politika', 0.6759346723556519),\n",
       " ('litiker', 0.6655194759368896),\n",
       " ('Berufspolitiker', 0.65301114320755),\n",
       " ('Politi', 0.6442322731018066)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.wv.most_similar(word, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Warenhaus', 0.43683958053588867),\n",
       " ('Peiritsch', 0.4329608082771301),\n",
       " ('2150', 0.3990057706832886),\n",
       " ('überdecken', 0.3787200450897217),\n",
       " ('Bravo', 0.37358352541923523),\n",
       " ('kommentarlos', 0.3728218972682953),\n",
       " ('Arena', 0.3688957691192627),\n",
       " ('Gilligan', 0.36179256439208984),\n",
       " ('Meyer', 0.35840052366256714),\n",
       " ('prominente', 0.3579070568084717)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wv.wv.most_similar(word, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(model, worda, wordb, wordc):\n",
    "    result = model.wv.most_similar(negative=[worda], positive=[wordb, wordc])\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'litiker'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(model_ft, 'Mann','Politiker','Frau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hübsch'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(model_wv, 'Mann','Politiker','Frau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save gensim models\n",
    "model_ft.save(\"../outputs/amc.fasttext.300.toy.model\")\n",
    "model_wv.save(\"../outputs/amc.word2vec.300.toy.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved gensim fastText model\n",
    "#model_ft = Word2Vec.load(\"../outputs/amc.fasttext.300.toy.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(for_word, w2v_model):\n",
    "    # trained fastText model dimention\n",
    "    dim_size = w2v_model.wv.vectors.shape[1]\n",
    "    arrays = np.empty((0, dim_size), dtype='f')\n",
    "    word_labels = [for_word]\n",
    "    color_list  = ['red']\n",
    "    # adds the vector of the query word\n",
    "    arrays = np.append(arrays, w2v_model.wv.__getitem__([for_word]), axis=0)\n",
    "    # gets list of most similar words\n",
    "    sim_words = w2v_model.wv.most_similar(for_word, topn=10)\n",
    "    # adds the vector for each of the closest words to the array\n",
    "    for wrd_score in sim_words:\n",
    "        wrd_vector = w2v_model.wv.__getitem__([wrd_score[0]])\n",
    "        word_labels.append(wrd_score[0])\n",
    "        color_list.append('green')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "    #---------------------- Apply PCA and tsne to reduce dimention --------------\n",
    "    # fit 2d PCA model to the similar word vectors\n",
    "    model_pca = PCA(n_components = 10).fit_transform(arrays)\n",
    "    # Finds 2d coordinates t-SNE\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(model_pca)\n",
    "    # Sets everything up to plot\n",
    "    df_plot = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
    "                            'y': [y for y in Y[:, 1]],\n",
    "                            'words_name': word_labels,\n",
    "                            'words_color': color_list})\n",
    "    #------------------------- tsne plot Python -----------------------------------\n",
    "    # plot dots with color and position\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "    plot_dot = sns.regplot(data=df_plot,\n",
    "                           x=\"x\",\n",
    "                           y=\"y\",\n",
    "                           fit_reg=False,\n",
    "                           marker=\"o\",\n",
    "                           ax=ax,\n",
    "                           scatter_kws={'s': 40,\n",
    "                                        'facecolors': df_plot['words_color']\n",
    "                                        }\n",
    "                           )\n",
    " \n",
    "    # Adds annotations with color one by one with a loop\n",
    "    for line in range(0, df_plot.shape[0]):\n",
    "         plot_dot.text(df_plot[\"x\"][line],\n",
    "                 df_plot['y'][line],\n",
    "                 '  ' + df_plot[\"words_name\"][line].title(),\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='bottom', size='medium',\n",
    "                 color=df_plot['words_color'][line],\n",
    "                 weight='normal'\n",
    "                ).set_size(15)\n",
    " \n",
    "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
    "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
    "    plt.title('t-SNE visualization for word \"{}'.format(for_word.title()) +'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne plot for top 10 similar word to 'chicken'\n",
    "tsne_plot(for_word=word, w2v_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
